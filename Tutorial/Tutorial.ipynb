{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91129cb1",
   "metadata": {},
   "source": [
    "# LimberJack.jl Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a2d09",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3418f80",
   "metadata": {},
   "source": [
    "The core of  $\\texttt{LimberJack.jl}$ is the $\\texttt{Cosmology}$ structure and its homonymous constructor. $\\texttt{Cosmology}$'s role is to contain all the information on how to compute the theoretical predictions. When the \\texttt{Cosmology} structure is initiated it computes theoretical predictions for the expansion history, comoving distance, the growth factor and the matter power spectrum according to the provided prescriptions. The computation of background quantities occurs within $\\texttt{core.jl}$ itself. However, the computation of the matter power spectrum takes place across three different modules, $\\texttt{boltzmann.jl}$, $\\texttt{growth.jl}$ and $\\texttt{halofit.jl}$, which compute the primordial matter power spectrum, the linear growth factor and the non-linear corrections respectively. The different predictions are evaluated at a grid of values which are then used build interpolators for each of the respective quantities. The interpolators are then stored inside the $\\texttt{Cosmology}$ structure. This allows the user to quickly compute the theoretical predictions at arbitrary values by using a series of public functions. These functions take the $\\texttt{Cosmology}$ structure and the necessary inputs. Inside these functions the corresponding interpolator is evaluated at the provided inputs to return the prediction to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate env\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "# Imports\n",
    "using LimberJack\n",
    "\n",
    "# create LimberJack.jl Cosmology instance\n",
    "cosmo = Cosmology() \n",
    "# same as \n",
    "# cosmology = Cosmology(|$\\Omega_m=0.3$|, |$\\Omega_b=0.05$|,\n",
    "#                       h=0.67, ns=0.96, |$\\sigma_8=0.81$|)     \n",
    " \n",
    "zs = [0.1, 0.5, 1.0, 3.0]\n",
    "H = cosmo.cpar.h*100*Ez(cosmo, zs)\n",
    "chi = comoving_radial_distance(cosmo, zs)\n",
    "Dz = growth_factor(cosmo, zs)\n",
    "fz = growth_rate(cosmo, zs)\n",
    "fs8z = fs8(cosmo, zs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff368c1c",
   "metadata": {},
   "source": [
    "Computing the matter power spectrum is just as easy. However, the computation is subject to a series of options that the user can alter. By default $\\texttt{Cosmology}$ will use the E\\&H formula to find the matter power spectrum and it will not apply non-linear corrections.  These settings can be changed by specifying the keyword arguments $\\texttt{tk\\_mode}$ and $\\texttt{pk\\_mode}$ which control the used transfer function and whether non-linear corrections are applied to the power spectrum respectively. In terms transfer function $\\texttt{LimberJack}$ offers two possibilities  $\\texttt{tk\\_mode}$ = $\\texttt{EisHu}$ (default) / $\\texttt{EmuPk}$ which correspond to using the Eisenstein and Hu formula or $\\texttt{:EmuPk}$. Similarly, $\\texttt{pk\\_mode}$ = $\\texttt{:linear}$ / $\\texttt{:Halofit}$ which determines whether or not non-linear corrections are applied using $\\texttt{Halofit}$. $\\texttt{LimberJack.jl}$ offers two distinct public functions to evaluate either the linear or non-linear matter power spectrum regardless of the choice in $\\texttt{pk\\_mode}$. However, if $\\texttt{pk\\_mode}$ = $\\texttt{:linear}$ the two functions will return the linear matter power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dae8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_lin_EisHu = Cosmology(Omega_m=0.25, Omega_b=0.03,\n",
    "                             h=0.70, ns=1.0,\n",
    "                             sigma_8=0.78,\n",
    "                             tk\\_mode=:EisHu,\n",
    "                             pk\\_mode=:linear) \n",
    "                             \n",
    "cosmo_nonlin_EisHu = Cosmology(Omega_m=0.25, Omega_b=0.03,\n",
    "                             h=0.70, ns=1.0,\n",
    "                             sigma_8=0.78,\n",
    "                             tk\\_mode=:EisHu,\n",
    "                             pk\\_mode=:Halofit) \n",
    "\n",
    "cosmo_nonlin_emupk = Cosmology(Omega_m=0.25, Omega_b=0.03,\n",
    "                             h=0.70, ns=1.0,\n",
    "                             sigma_8=0.78,\n",
    "                             tk\\_mode=:EmuPk,\n",
    "                             pk\\_mode=:Halofit)\n",
    "\n",
    "zs = [0.1, 0.3, 0.5]\n",
    "ks = [100, 300, 1000]\n",
    "lin_eh_Pks = lin_Pk(cosmo_lin_EisHu, ks, zs) = nonlin_Pk(cosmo_lin_EisHu, ks, zs)\n",
    "nonlin_eh_Pks = nonlin_Pk(cosmo_nonlin_EisHu, ks, zs)\n",
    "nonlin_emupk_Pks = nonlin_Pk(cosmo_nonlin_emupk, ks, zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eeadb3",
   "metadata": {},
   "source": [
    "Computing angular power spectra is a slightly more involved process. An example of how this is done in $\\texttt{LimberJack}$ can be found below. In this code we can see that first a $\\texttt{Cosmology}$ structure must be initiated. The $\\texttt{Cosmology}$ structure automatically computes the matter power spectrum given the user specifications. Then the user must compute the distance kernels of the relevant tracers by proving the corresponding  $\\texttt{LimberJack}$ public functions with the $\\texttt{Cosmology}$ structure and the distribution of sources. Moreover, different tracers can be impacted by different systematic effects. These systematics are accounted by incorporating a series of nuisance parameters that can also be provided to the tracers public functions of  $\\texttt{LimberJack}$. The output of the tracer functions is a $\\texttt{Tracer}$ structure that hosts an interpolator for the corresponding distance kernel and the corrections. The angular power spectra can computed by providing the $\\texttt{AngularCls}$ public function with the aforementioned $\\texttt{Cosmology}$ and $\\texttt{Tracer}$ objects as well as the desired multipoles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f74cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate cosmology\n",
    "cosmo = Cosmology()\n",
    "\n",
    "# Define a distribution of sources\n",
    "z = Vector(range(0., stop=2., length=256))\n",
    "nz = @. exp(-0.5*((z-0.5)/0.05)^2)\n",
    "\n",
    "# Create tracer objects\n",
    "bias = 1.0 # Galaxy-mass bias\n",
    "tg = NumberCountsTracer(cosmo, z, nz; b=bias)\n",
    "\n",
    "mbias = 0.0 # shape multiplicative bias\n",
    "A_IA = 0.0 # Amplitude of intrinsic alignments power spectrum\n",
    "alpha_IA = 0.0 # Slope of intrinsic alignments power spectrum\n",
    "ts = WeakLensingTracer(cosmo, z, nz;\n",
    "                       m=mbias, IA_params=[A_IA, alpha_IA])\n",
    "\n",
    "tk = CMBLensingTracer(cosmo)\n",
    "\n",
    "# Compute power spectra\n",
    "ls = [10.0, 30.0, 100.0, 300.0, 1000.0]\n",
    "Cl_gg = angularCℓs(cosmo, tg, tg, ls)\n",
    "Cl_gs = angularCℓs(cosmo, tg, ts, ls)\n",
    "Cl_ss = angularCℓs(cosmo, ts, ts, ls)\n",
    "Cl_gk = angularCℓs(cosmo, tg, tk, ls)\n",
    "Cl_sk = angularCℓs(cosmo, ts, tk, ls);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda2e2a",
   "metadata": {},
   "source": [
    "## Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81f5a6",
   "metadata": {},
   "source": [
    "Finally, we show how to use $\\texttt{Turing}$ in unison with $\\texttt{LimberJack}$ to build and sample an statistical model for a the DESY1 3x2 analysis. The first step is to load the data. For this purpose we will use the libraries $\\texttt{YAML}$ and $\\texttt{sacc}$, ubiquitous in astrophysics. $\\texttt{Julia}$ counts with a native implementation of $\\texttt{YAML}$ but not of $\\texttt{sacc}$. However, calling $\\texttt{Python}$ libraries from $\\texttt{Julia}$ is extremely simple thanks to the $\\texttt{PythonCall.jl}$ library.  $\\texttt{PythonCall.jl}$ allows us to import $\\texttt{sacc.py}$ as a $\\texttt{Julia}$ module and read files entirely within $\\texttt{Julia}$. Note that in order to this we must first install $\\texttt{sacc}$ in the $\\texttt{Python}$ environment of $\\texttt{LimberJack.jl}$ or point $\\texttt{PythonCall}$ to our local $\\texttt{Pytthon}$ installation. Instructions on how to do this can be found in the $\\texttt{LimberJack}$ GitHub.  Once the data are loaded they must be passed to the $\\texttt{LimberJack.jl}$ public function $\\texttt{make\\_data}$ which turns the files into $\\texttt{Julia}$ structures that $\\texttt{LimberJack.jl}$ can easily manage.\n",
    "\n",
    "After that, the user can use $\\texttt{Turing.jl}$'s $\\texttt{@model}$ macro to define an statistical model. Inside the model, the user must define the priors for the parameters of the model using $\\texttt{Distributions.jl}$. Note that while the cosmology parameters can be directly passed to the $\\texttt{Cosmology}$ structure constructor the nuisance parameters must be stored inside a $\\texttt{Julia}$ dictionary. The name of these parameters inside the dictionary must follow a strict convention \"$\\texttt{tracer\\_name}$ + __ + $\\texttt{bin\\_number}$ + _ + $\\texttt{nuisance\\_parameter\\_name}$\".\n",
    "\n",
    "In order to obtain the theoretical prediction for the DESY1 3x2 analysis data vector the user must provide the just initiated $\\texttt{Cosmology}$ structure and the $\\texttt{meta}$ and $\\texttt{files}$ structures generated by $\\texttt{make\\_data}$ to the public function $\\texttt{Theory}$. Moreover, the user must also provide the nuisance parameter dictionary using the $\\texttt{Nuisances}$ keyword argument. The $\\texttt{Theory}$ function orchestrates the computation of the theory vector, computing the necessary distance kernels and evaluating the angular power spectra in the correct order. \n",
    "\n",
    "Once a theoretical prediction has been obtained, the user must define how the data is distributed with respect to the theory prediction. In the case of a Gaussian likelihood, this corresponds to a multivariate Gaussian distribution with mean the theory prediction and covariance matrix the data covariance matrix. All is left is to do is to use $\\texttt{Turing.jl}$ to condition the model on the observations , define the sampler we wish to use and sample the model. For a more thorough explanation of how to use $\\texttt{Turing.jl}$ and its different options please see $\\texttt{Turing.jl}$'s documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962523e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "using LinearAlgebra\n",
    "using Turing\n",
    "using LimberJack\n",
    "using YAML\n",
    "using PythonCall\n",
    "sacc = pyimport(\"sacc\");\n",
    "\n",
    "# Load data\n",
    "sacc_path = \"cls_FD_covG.fits\"\n",
    "yaml_path = \"DESY1.yml\"\n",
    "sacc_file = sacc.Sacc().load_fits(sacc_path)\n",
    "yaml_file = YAML.load_file(yaml_path)\n",
    "meta, files = make_data(sacc_file, yaml_file)\n",
    "data = meta.data\n",
    "cov = meta.cov\n",
    "\n",
    "# Define model\n",
    "@model function model(data;\n",
    "    meta=meta, \n",
    "    files=files)\n",
    "    Ωm ~ Uniform(0.2, 0.6)\n",
    "    Ωb ~ Uniform(0.028, 0.065)\n",
    "    h ~ TruncatedNormal(0.72, 0.05, 0.64, 0.82)\n",
    "    σ8 ~ Uniform(0.4, 1.2)\n",
    "    ns ~ Uniform(0.84, 1.1)\n",
    "\n",
    "    DESgc__0_b ~ Uniform(0.8, 3.0)\n",
    "    DESgc__1_b ~ Uniform(0.8, 3.0)\n",
    "    DESgc__2_b ~ Uniform(0.8, 3.0)\n",
    "    DESgc__3_b ~ Uniform(0.8, 3.0)\n",
    "    DESgc__4_b ~ Uniform(0.8, 3.0)\n",
    "    DESgc__0_dz ~ TruncatedNormal(0.0, 0.007, -0.2, 0.2)\n",
    "    DESgc__1_dz ~ TruncatedNormal(0.0, 0.007, -0.2, 0.2)\n",
    "    DESgc__2_dz ~ TruncatedNormal(0.0, 0.006, -0.2, 0.2)\n",
    "    DESgc__3_dz ~ TruncatedNormal(0.0, 0.01, -0.2, 0.2)\n",
    "    DESgc__4_dz ~ TruncatedNormal(0.0, 0.01, -0.2, 0.2)\n",
    "    DESwl__0_dz ~ TruncatedNormal(-0.001, 0.016, -0.2, 0.2)\n",
    "    DESwl__1_dz ~ TruncatedNormal(-0.019, 0.013, -0.2, 0.2)\n",
    "    DESwl__2_dz ~ TruncatedNormal(0.009, 0.011, -0.2, 0.2)\n",
    "    DESwl__3_dz ~ TruncatedNormal(-0.018, 0.022, -0.2, 0.2)\n",
    "    DESwl__0_m ~ Normal(0.012, 0.023)\n",
    "    DESwl__1_m ~ Normal(0.012, 0.023)\n",
    "    DESwl__2_m ~ Normal(0.012, 0.023)\n",
    "    DESwl__3_m ~ Normal(0.012, 0.023)\n",
    "    A_IA ~ Uniform(-5, 5) \n",
    "    alpha_IA ~ Uniform(-5, 5)\n",
    "\n",
    "    nuisances = Dict(\"DESgc__0_b\" => DESgc__0_b,\n",
    "                     \"DESgc__1_b\" => DESgc__1_b,\n",
    "                     \"DESgc__2_b\" => DESgc__2_b,\n",
    "                     \"DESgc__3_b\" => DESgc__3_b,\n",
    "                     \"DESgc__4_b\" => DESgc__4_b,\n",
    "                     \"DESgc__0_dz\" => DESgc__0_dz,\n",
    "                     \"DESgc__1_dz\" => DESgc__1_dz,\n",
    "                     \"DESgc__2_dz\" => DESgc__2_dz,\n",
    "                     \"DESgc__3_dz\" => DESgc__3_dz,\n",
    "                     \"DESgc__4_dz\" => DESgc__4_dz,\n",
    "                     \"DESwl__0_dz\" => DESwl__0_dz,\n",
    "                     \"DESwl__1_dz\" => DESwl__1_dz,\n",
    "                     \"DESwl__2_dz\" => DESwl__2_dz,\n",
    "                     \"DESwl__3_dz\" => DESwl__3_dz,\n",
    "                     \"DESwl__0_m\" => DESwl__0_m,\n",
    "                     \"DESwl__1_m\" => DESwl__1_m,\n",
    "                     \"DESwl__2_m\" => DESwl__2_m,\n",
    "                     \"DESwl__3_m\" => DESwl__3_m,\n",
    "                     \"A_IA\" => A_IA,\n",
    "                     \"alpha_IA\" => alpha_IA,)\n",
    "\n",
    "    cosmology = Cosmology(Ωm= Ωm,  Ωb=Ωb, h=h, ns=ns, σ8=σ8,\n",
    "                          tk_mode=:EisHu,\n",
    "                          pk_mode=:Halofit)\n",
    "\n",
    "    theory = Theory(cosmology, meta, files; Nuisances=nuisances)\n",
    "    data ~ MvNormal(theory, cov)\n",
    "end\n",
    "\n",
    "# Condition model on data\n",
    "cond_model = model(data)\n",
    "\n",
    "# Define sampler\n",
    "nadapts = 500\n",
    "TAP = 0.65\n",
    "sampler = NUTS(adaptation, TAP)\n",
    "\n",
    "# Sample model \n",
    "iterations = 1000\n",
    "chain = sample(cond_model, sampler, iterations) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82475a5",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a28621",
   "metadata": {},
   "source": [
    "In order to plot the results I use ```GetDist.py``` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dcda4b",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "import sacc\n",
    "\n",
    "def add_chains(path):\n",
    "    chains = []\n",
    "    i = 1 \n",
    "    while os.path.isfile(path+\"chain_{}.csv\".format(i)):\n",
    "        chain = pd.read_csv(path+\"chain_{}.csv\".format(i))\n",
    "        chains.append(chain)\n",
    "        i += 1\n",
    "    return pd.concat(chains)\n",
    "\n",
    "test = add_chains(\"../chains/test_TAP_0.65/\")\n",
    "\n",
    "labels_dict = {'eta': '\\eta',\n",
    "               'l': 'l',\n",
    "               'h': 'h',\n",
    "               'Ωm': '\\Omega_m',\n",
    "               'Ωb': '\\Omega_b',\n",
    "               'ns': 'n_s',\n",
    "               's8': '\\sigma_8',\n",
    "               'S8': 'S_8',\n",
    "               'A_IA': 'A_{IA}',\n",
    "               'alpha_IA': r'\\alpha_{IA}',\n",
    "               'DESgc__0_0_dz': 'dz_{DESY1gc \\, 0}',\n",
    "               \n",
    "               'DESgc__1_0_dz': 'dz_{DESY1gc \\, 1}',\n",
    "               'DESgc__2_0_dz': 'dz_{DESY1gc \\, 2}',\n",
    "               'DESgc__3_0_dz': 'dz_{DESY1gc \\, 3}',\n",
    "               'DESgc__4_0_dz': 'dz_{DESY1gc \\, 4}',\n",
    "               \n",
    "               'DESwl__0_e_dz': 'dz_{DESY1wl \\, 0}',\n",
    "               'DESwl__1_e_dz': 'dz_{DESY1wl \\, 1}',\n",
    "               'DESwl__2_e_dz': 'dz_{DESY1wl \\, 2}',\n",
    "               'DESwl__3_e_dz': 'dz_{DESY1wl \\, 3}',\n",
    "               \n",
    "               'DESgc__0_0_b': 'b_{DESY1 \\, 0}',\n",
    "               'DESgc__1_0_b': 'b_{DESY1 \\, 1}',\n",
    "               'DESgc__2_0_b': 'b_{DESY1 \\, 2}',\n",
    "               'DESgc__3_0_b': 'b_{DESY1 \\, 3}',\n",
    "               'DESgc__4_0_b': 'b_{DESY1 \\, 4}',\n",
    "               \n",
    "               'DESwl__0_e_m': 'm_{DESY1 \\, 0 }',\n",
    "               'DESwl__1_e_m': 'm_{DESY1 \\, 1 }',\n",
    "               'DESwl__2_e_m': 'm_{DESY1 \\, 2 }', \n",
    "               'DESwl__3_e_m': 'm_{DESY1 \\, 3 }',\n",
    "               \n",
    "               'eBOSS__0_0_b': 'b_{eBOSS \\, 0}',\n",
    "               'eBOSS__1_0_b': 'b_{eBOSS \\, 1}',\n",
    "               \n",
    "               \"DECALS__0_0_b\": 'b_{DECALS \\, 0}',\n",
    "               \"DECALS__1_0_b\": 'b_{DECALS \\, 1}',\n",
    "               \"DECALS__2_0_b\": 'b_{DECALS \\, 2}',\n",
    "               \"DECALS__3_0_b\": 'b_{DECALS \\, 3}',\n",
    "               \n",
    "               \"DECALS__0_0_dz\": 'dz_{DECALS \\, 0}',\n",
    "               \"DECALS__1_0_dz\": 'dz_{DECALS \\, 1}',\n",
    "               \"DECALS__2_0_dz\": 'dz_{DECALS \\, 2}',\n",
    "               \"DECALS__3_0_dz\": 'dz_{DECALS \\, 3}',\n",
    "\n",
    "               \"KiDS1000__0_e_dz\": 'dz_{KiDS \\, 0}',\n",
    "               \"KiDS1000__1_e_dz\": 'dz_{KiDS \\, 1}',\n",
    "               \"KiDS1000__2_e_dz\": 'dz_{KiDS \\, 2}',\n",
    "               \"KiDS1000__3_e_dz\": 'dz_{KiDS \\, 3}',\n",
    "               \"KiDS1000__4_e_dz\": 'dz_{KiDS \\, 4}',\n",
    "               \n",
    "               \"KiDS1000__0_e_m\": 'm_{KiDS \\, 0}',\n",
    "               \"KiDS1000__1_e_m\": 'm_{KiDS \\, 1}',\n",
    "               \"KiDS1000__2_e_m\": 'm_{KiDS \\, 2}',\n",
    "               \"KiDS1000__3_e_m\": 'm_{KiDS \\, 3}',\n",
    "               \"KiDS1000__4_e_m\": 'm_{KiDS \\, 4}',\n",
    "               \n",
    "               \"v[1]\": \"v_{1}\", \"v[2]\": \"v_{2}\",\n",
    "               \"v[3]\": \"v_{3}\", \"v[4]\": \"v_{4}\",\n",
    "               \"v[5]\": \"v_{5}\", \"v[6]\": \"v_{6}\",\n",
    "               \"v[7]\": \"v_{7}\", \"v[8]\": \"v_{8}\", \n",
    "               \"v[9]\": \"v_{9}\", \"v[10]\": \"v_{10}\",\n",
    "               \"v[11]\": \"v_{11}\"}\n",
    "\n",
    "def make_chain(file, label, ranges=dict({})):\n",
    "    params = np.array(list(file.keys()))\n",
    "    names = []\n",
    "    labels = []\n",
    "    samples = []\n",
    "    print()\n",
    "    print(label)\n",
    "    for param in params:\n",
    "        print(param)\n",
    "        if param in labels_dict.keys():\n",
    "            print(param)\n",
    "            names.append(param) \n",
    "            labels.append(labels_dict[param]) \n",
    "            samples.append(file[param])\n",
    "    if ('s8' in params) & ('Ωm' in params):\n",
    "        print('S8')\n",
    "        names.append('S8')\n",
    "        labels.append(labels_dict['S8'])\n",
    "        samples.append(file['s8']*np.sqrt(file['Ωm']/0.3))\n",
    "\n",
    "    names = np.array(names)\n",
    "    labels = np.array(labels)\n",
    "    samples = np.transpose(np.array(samples))\n",
    "    print(\"========\")\n",
    "\n",
    "    return MCSamples(samples=samples, names=names, labels=labels, label=label, ranges=ranges,  \n",
    "                    settings={'mult_bias_correction_order':0,'smooth_scale_2D':0.4, 'smooth_scale_1D':0.3})\n",
    "\n",
    "test_samples = make_chain(test, \"Test\");\n",
    "\n",
    "g = plots.getSubplotPlotter(subplot_size=4)\n",
    "g.triangle_plot(test_samples, filled=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
